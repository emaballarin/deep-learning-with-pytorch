{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Handling [tensors](https://pytorch.org/docs/stable/tensors.html?highlight=tensor#torch.Tensor) with PyTorch\n",
    "At its core, PyTorch is a library that provides multidimensional arrays, called tensors in\n",
    "PyTorch parlance, and an extensive library of operations on them is provided by the torch module. Both tensors and related operations can run on the CPU or GPU. The second core thing that PyTorch allows tensors to keep track of the operations performed on them and to compute derivatives of an output with respect to any of its inputs analytically via backpropagation.\n",
    "\n",
    "**Key points**\n",
    "\n",
    "- Numbers in Python are full-fledged objects.\n",
    "- Lists in Python are meant for sequential collections of objects.\n",
    "- The Python interpreter is slow compared with optimized, compiled code\n",
    "\n",
    "![memory](./images/memory.png)\n",
    "\n",
    "PyTorch tensors or NumPy arrays, on the other hand, are views over (typically) contiguous memory blocks containing unboxed C numeric types, not Python objects. So a 1D tensor of 1 million float numbers requires 4 million contiguous bytes to be stored, plus a small overhead for the metadata (dimensions, numeric type, and so on).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1.4.0\n"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "print(torch.__version__) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pytorch-Numpy interoperability\n",
    "\n",
    "Values are allocated in contiguous chunks of memory, managed by torch.Storage instances. A storage is a one-dimensional array of numerical data, such as a contiguous block of memory containing numbers of a given type, perhaps a float or int32. A PyTorch Tensor is a view over such a Storage thatâ€™s capable of indexing into that storage by using an offset and per-dimension strides\n",
    "\n",
    "![storage](./images/storage.png)\n",
    "\n",
    "\n",
    "Some useful methods:\n",
    "- .tensor() will make a copy of the argument\n",
    "- .numpy() will return a view on the same memory elements\n",
    "- .from_numpy() will return a view on the same memory elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Numpy array:\n[[ 0.38141731  1.27508522 -1.8911128 ]\n [ 2.04102255  0.66322738  1.58110616]]\n\nTensor :\ntensor([[ 0.3814,  1.2751, -1.8911],\n        [ 2.0410,  0.6632,  1.5811]], dtype=torch.float64)\n\n#####\nWe modify the element (0, 0) of the tensor object\nTensor :\ntensor([[10.0000,  1.2751, -1.8911],\n        [ 2.0410,  0.6632,  1.5811]], dtype=torch.float64)\n\nNumpy array:\n[[ 0.38141731  1.27508522 -1.8911128 ]\n [ 2.04102255  0.66322738  1.58110616]]\n\n"
    }
   ],
   "source": [
    "arr_np = np.random.randn(2, 3)\n",
    "print(\"Numpy array:\\n{}\\n\".format(arr_np))\n",
    "\n",
    "tens = torch.tensor(arr_np) # change printing precision with torch.set_printoptions()\n",
    "print(\"Tensor :\\n{}\\n\".format(tens))\n",
    "\n",
    "\n",
    "print(\"#####\\nWe modify the element (0, 0) of the tensor object\")\n",
    "tens[0, 0] = 10\n",
    "print(\"Tensor :\\n{}\\n\".format(tens))\n",
    "print(\"Numpy array:\\n{}\\n\".format(arr_np))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Numpy array obtained with tens.numpy():\n[[10.          1.27508522 -1.8911128 ]\n [ 2.04102255  0.66322738  1.58110616]]\n\nChanging this numpy array will change our tensor too:\ntensor([[10.0000, 20.0000, -1.8911],\n        [ 2.0410,  0.6632,  1.5811]], dtype=torch.float64)\n\n"
    }
   ],
   "source": [
    "arr_from_tens = tens.numpy()\n",
    "print(\"Numpy array obtained with tens.numpy():\\n{}\\n\".format(arr_from_tens)) # it is a view on the same storage\n",
    "\n",
    "arr_from_tens[0, 1] = 20\n",
    "print(\"Changing this numpy array will change our tensor too:\\n{}\\n\".format(tens))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With slicing we get different tensor views on the same underlying data. We can get copied pieces of those view as python numbers or lists with tens.item() for single values, or tens.tolist().\n",
    "To check that they are copies, we can use np.shares_memory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "True\nFalse\nFalse\n"
    }
   ],
   "source": [
    "tens_first_row = tens[0]\n",
    "tens_element_as_py_obj = tens[0, 0].item()\n",
    "tens_as_list = tens.tolist()\n",
    "\n",
    "print(np.shares_memory(tens, tens_first_row))\n",
    "print(np.shares_memory(tens, tens_element_as_py_obj))\n",
    "print(np.shares_memory(tens, tens_as_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of our tensor is given by the way we strides along the underlying storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([2, 3])\ntorch.Size([2, 3])\n"
    }
   ],
   "source": [
    "print(tens.size())\n",
    "print(tens.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Factory functions](https://pytorch.org/cppdocs/notes/tensor_creation.html#picking-a-factory-function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[3],\n        [3]])\ntensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\ntensor([0.0000, 0.1429, 0.2857, 0.4286, 0.5714, 0.7143, 0.8571, 1.0000])\ntensor([[1., 0.],\n        [0., 1.]])\ntensor([[0., 0., 0.],\n        [0., 0., 0.],\n        [0., 0., 0.]])\ntensor([[1., 1.]])\ntensor([ 0.6068, -0.1782,  0.1100])\ntensor([ 3, 11,  2,  4,  5,  8, 10,  0,  7,  6,  1,  9])\n"
    }
   ],
   "source": [
    "print(torch.randint(0, 10, size=(2, 1)))\n",
    "print(torch.arange(10))\n",
    "print(torch.linspace(0, 1, 8))\n",
    "print(torch.eye(2))\n",
    "print(torch.zeros(3,3))\n",
    "print(torch.ones(1, 2))\n",
    "print(torch.randn(3))\n",
    "print(torch.randperm(12))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[1., 0.],\n        [0., 1.]])\ntensor([[-9.6760e-35,  3.0658e-41, -9.6769e-35],\n        [ 3.0658e-41,  7.5745e+23,  7.0078e+22]])\n"
    }
   ],
   "source": [
    "print(torch.FloatTensor([[1, 0], [0, 1]]))\n",
    "print(torch.Tensor(2, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "torch.empty() allows to construct a tensor without initializing any value. \n",
    "\n",
    "We can sample in place from a broader range of distributions by using Tensor's methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[-9.7831e-35,  3.0658e-41, -9.6760e-35],\n        [ 3.0658e-41,  8.9683e-44,  0.0000e+00]])\ntensor([ -0.0338, -30.7488,  -2.6397])\ntensor([1., 1., 1.])\n"
    }
   ],
   "source": [
    "print(torch.empty(2, 3))\n",
    "print(torch.empty(3).cauchy_())\n",
    "print(torch.empty(3).geometric_(0.7))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trailing underscore concerns in-place methods, i.e. those methods who transforms the input without making a copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([2., 2.])\ntensor([1.4142, 1.4142])\nFalse\ntensor([1.4142, 1.4142])\n"
    }
   ],
   "source": [
    "twotwo = 2 * torch.ones(2)\n",
    "print(twotwo)\n",
    "\n",
    "twotwo_sqrt = torch.sqrt(twotwo)\n",
    "print(twotwo_sqrt)\n",
    "\n",
    "print(np.shares_memory(twotwo, twotwo_sqrt))\n",
    "\n",
    "twotwo.sqrt_()\n",
    "print(twotwo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Numeric types](https://pytorch.org/docs/stable/tensors.html#torch-tensor) and casting\n",
    "The dtype argument to tensor constructors (that is, functions such as tensor, zeros, and ones) specifies the numerical data type that will be contained in the tensor. The data type specifies the possible values that the tensor can hold (integers versus floating-point numbers) and the number of bytes per value.\n",
    "\n",
    "torch.Tensor is an alias for the default tensor type, torch.FloatTensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.FloatTensor\ntensor([0, 1, 2], dtype=torch.int16)\ntensor([0, 1, 2], dtype=torch.int16)\ntensor([1., 1., 1.], dtype=torch.float64)\ntensor([1., 1., 1.], dtype=torch.float64)\n"
    }
   ],
   "source": [
    "print(torch.zeros(2).type())\n",
    "print(torch.tensor([0, 1, 2], dtype=torch.short))\n",
    "print(torch.tensor([0, 1, 2]).short())\n",
    "\n",
    "print(torch.ones(3, dtype=torch.double))\n",
    "print(torch.ones(3).double())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the dtype, a PyTorch tensor has a notion of device, which specifies if the operations on that tensor will be carried out by the CPU or a GPU, if one is present on the machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([1., 1., 1.], device='cuda:0')\ntensor([1., 1., 1.], device='cuda:0')\ntensor([1., 1., 1.], device='cuda:0')\ntorch.cuda.FloatTensor\n"
    }
   ],
   "source": [
    "print(torch.ones(3, device='cuda'))\n",
    "print(torch.ones(3).cuda())\n",
    "print(torch.ones(3).to('cuda'))\n",
    "\n",
    "print(torch.ones(3).to('cuda').type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations on tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "a + b = tensor([[ 0.8964],\n        [ 1.7367],\n        [-0.2284]])\n"
    }
   ],
   "source": [
    "a = torch.randn(3, 1)\n",
    "b = torch.randn_like(a)\n",
    "\n",
    "print(\"a + b = {}\".format(a + b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "a @ b.T = tensor([[ 0.1979,  0.1808, -0.3951],\n        [ 0.6423,  0.5869, -1.2822],\n        [ 0.3899,  0.3563, -0.7785]])\n"
    }
   ],
   "source": [
    "# about `at` operator (a.k.a. `@`): https://www.python.org/dev/peps/pep-0465/\n",
    "print(\"a @ b.T = {}\".format(a @ b.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "a.T = tensor([[0.3935, 1.2772, 0.7755]])\n"
    }
   ],
   "source": [
    "# dimensions inversion\n",
    "print(\"a.T = {}\".format(a.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "a.t() = tensor([[0.3935, 1.2772, 0.7755]])\n"
    }
   ],
   "source": [
    "# matrix transpose (https://pytorch.org/docs/stable/tensors.html#torch.Tensor.t)\n",
    "print(\"a.t() = {}\".format(a.t()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([2, 3, 4, 5, 6])\ntorch.Size([6, 5, 4, 3, 2])\ntorch.Size([4, 3, 2, 5, 6])\n"
    }
   ],
   "source": [
    "c = torch.randint(0, 10, size=(2, 3, 4, 5, 6))\n",
    "print(c.size())\n",
    "print(c.T.size())\n",
    "print(c.transpose(0, 2).size())\n",
    "# print(c.t().size()) # error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "5\n720\n720\n"
    }
   ],
   "source": [
    "print(c.dim()) # the order of the tensor\n",
    "print(c.numel())\n",
    "print(torch.numel(c))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[  0,   1],\n        [  2, 467]])\n"
    }
   ],
   "source": [
    "d = torch.tensor([[0, 1], [2, 467]])\n",
    "print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[  0,   1,   2, 467]])\n"
    }
   ],
   "source": [
    "print(d.view(-1, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "2\n"
    }
   ],
   "source": [
    "print(d.dim())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "torch.Size([1, 2, 2])\n"
    }
   ],
   "source": [
    "print(d.unsqueeze(0).size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([[  0,   1],\n        [  2, 467]])\ntensor([[33, 33],\n        [33, 33]])\n"
    }
   ],
   "source": [
    "print(d.squeeze(0))\n",
    "print(d.fill_(33))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([[33, 33],\n        [33, 33]])"
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "tensor([33, 33, 33, 33])"
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "d.resize_(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tensor([33, 33, 33, 33,  1,  1,  1,  1])\n"
    }
   ],
   "source": [
    "e = torch.ones_like(d)\n",
    "print(torch.cat([d, e], dim=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Device: cuda:0\n"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print('Device: {}'.format(device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [.to()](https://pytorch.org/docs/stable/tensors.html#torch.Tensor.to) method returns a new tensor. We can use it to convert either its type and its device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "e = e.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources\n",
    "\n",
    "Pictures from: [Deep Learning with Pytorch, *Essential Excerpts* - Stevens, Antiga, Viehmann](https://pytorch.org/assets/deep-learning/Deep-Learning-with-PyTorch.pdf) ([full book](https://www.manning.com/books/deep-learning-with-pytorch))\n",
    "\n",
    "[Official documentation](https://pytorch.org/docs/stable/index.html)\n",
    "\n",
    "[Tutorials](https://pytorch.org/tutorials/)\n",
    "\n",
    "[Nice guy talking about tensors](https://www.youtube.com/watch?v=f5liqUk0ZTw)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('radler-local': conda)",
   "language": "python",
   "name": "python37664bitradlerlocalcondac4d2490083224f6ab78d4c3c1651fc34"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}